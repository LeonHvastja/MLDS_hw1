{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41607861",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44ec2c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    \"\"\"Assumes the tki-resistance.csv is in our working directory.\n",
    "    Returns (X_train, y_train, X_test, y_test)\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(\"tki-resistance.csv\")\n",
    "    data[\"Class\"] = data[\"Class\"].map({\"Bcr-abl\":0, \"Wild type\":1})\n",
    "    X, y = np.array(data)[:,0:-1], np.array(data)[:,-1]\n",
    "    X_train, y_train, X_test, y_test = X[:130], y[:130], X[130:], y[130:]\n",
    "\n",
    "    return ((X_train, y_train), (X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4b3c5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4e6847f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_columns(X, rand):\n",
    "    return range(X.shape[1])\n",
    "\n",
    "\n",
    "def random_sqrt_columns(X, rand):\n",
    "    c = rand.sample(range(0, X.shape[1]), round(X.shape[1]**0.5))\n",
    "    return c\n",
    "\n",
    "\n",
    "class Tree:\n",
    "\n",
    "    def __init__(self, rand=None,\n",
    "                 get_candidate_columns=all_columns,\n",
    "                 min_samples=2):\n",
    "        self.rand = rand  # for replicability\n",
    "        self.get_candidate_columns = get_candidate_columns  # needed for random forests\n",
    "        self.min_samples = min_samples \n",
    "    \n",
    "    def build(self, X: np.array, y: np.array):\n",
    "        \"\"\"\n",
    "        Recusrively build a tree, stop recursion when a split has a child node with gini impurity 0 or\n",
    "        when we have less than min_samples samples.\n",
    "        \"\"\"\n",
    "        if (len(y) == 0): # for an empty branch just return 0\n",
    "            return TreeNode(None, None, 0)\n",
    "        if (len(y) < self.min_samples): # we are in a leaf node\n",
    "            return TreeNode(None, None, round(np.mean(y))) # make the majority class the prediction for this node\n",
    "        if (np.all(y == 1)): # check if we have a node with all ones\n",
    "            return TreeNode(None, None, 1)\n",
    "        if (np.all(y == 0)):\n",
    "            return TreeNode(None, None, 0)\n",
    "        \n",
    "        decision_rule = self.find_decision_rule(X, y)\n",
    "        feature, split_value = decision_rule\n",
    "        \n",
    "        left_i = np.where(X[:,feature] < split_value)\n",
    "        right_i = np.where(X[:, feature] >= split_value)\n",
    "        \n",
    "        left_subtree = Tree()\n",
    "        right_subtree = Tree()\n",
    "        \n",
    "        return TreeNode(left_subtree.build(X[left_i], y[left_i]),\n",
    "                        right_subtree.build(X[right_i], y[right_i]), \n",
    "                        decision_rule) \n",
    "    \n",
    "    \n",
    "    def find_decision_rule(self, X, y):\n",
    "        \"\"\"\n",
    "        Input: X - data, y - labels\n",
    "        Output: A tuple (left, right, decision_rule), left indicies, right indicies and rule. Rule itself is a tuple\n",
    "        of the index of the feature to split on and the value of where to split.)\n",
    "        \"\"\"\n",
    "        decision_rule = None\n",
    "        best_info_gain = 0\n",
    "\n",
    "        for feature in self.get_candidate_columns(X, self.rand):\n",
    "            values = X[:, feature]\n",
    "            sorted_indices = np.argsort(values)\n",
    "            sorted_values = values[sorted_indices]\n",
    "            for i in range(len(sorted_values) - 1):\n",
    "                current_info_gain = self.information_gain(y[sorted_indices], np.arange(0,i+1), np.arange(i+1, len(values)))\n",
    "                \n",
    "                if(current_info_gain > best_info_gain):\n",
    "                    split_value = self.midpoint(i, sorted_values)\n",
    "                    best_info_gain = current_info_gain\n",
    "                    decision_rule = (feature, split_value)\n",
    "\n",
    "        return decision_rule\n",
    "                \n",
    "    def midpoint(self, index, y):\n",
    "        \"\"\"Finds the average value of entires at index i and i+1 in a presumably sorted array.\"\"\"\n",
    "        return (y[index] + y[index + 1])/2\n",
    "    \n",
    "    def information_gain(self, y , left_partition_indicies, right_partition_indicies):\n",
    "        \"\"\"\n",
    "        Input: Takes an array of labels and the indicies of which belong to the lefr and right partition.\n",
    "        Output: Returns information gain for this particular split.\n",
    "        \"\"\"\n",
    "        n_left = len(left_partition_indicies)\n",
    "        n_right = len(right_partition_indicies)\n",
    "        n = n_left + n_right\n",
    "\n",
    "        l_weight = n_left/n\n",
    "        r_weight = n_right/n\n",
    "\n",
    "        inf_gain = (self.gini_impurity(y) \n",
    "                    - self.gini_impurity(y[left_partition_indicies])*l_weight \n",
    "                    - self.gini_impurity(y[right_partition_indicies])*r_weight)\n",
    "\n",
    "        return inf_gain\n",
    "\n",
    "    def gini_impurity(self, y):\n",
    "        \"\"\"\n",
    "        We can use this simplified version because we are solving a strictly binary classification problem, \n",
    "        assume y is a numpy array with values of 0 or 1.\n",
    "        \"\"\"\n",
    "\n",
    "        label_one_probability = sum(y)/len(y)\n",
    "\n",
    "        return 1 - ((label_one_probability)**2 + (1-label_one_probability)**2)\n",
    "\n",
    "\n",
    "class TreeNode:\n",
    "    \n",
    "    def __init__(self, left, right, decision_rule):\n",
    "        \"\"\"Left and right are TreeNode objects. Decision rule is either a tuple with a feature and value \n",
    "        to split on or a single value which determines the leaf's predicted label.\n",
    "        \"\"\"\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.decision_rule = decision_rule\n",
    "\n",
    "    def predict(self, X):\n",
    "        prediction = np.empty(len(X))\n",
    "        \n",
    "        if ((self.left is None) and (self.right is None)): # we are in a leaf node\n",
    "            return self.decision_rule\n",
    "        \n",
    "        # get left and right indices\n",
    "        left_i = np.where(X.T[self.decision_rule[0]] < self.decision_rule[1])\n",
    "        right_i = np.where(X.T[self.decision_rule[0]] >= self.decision_rule[1])\n",
    "        \n",
    "        left_prediction = self.left.predict(X[left_i])\n",
    "        right_prediction = self.right.predict(X[right_i])\n",
    "        \n",
    "        prediction[left_i] = left_prediction\n",
    "        prediction[right_i] = right_prediction\n",
    "               \n",
    "        return prediction\n",
    "\n",
    "\n",
    "class RandomForest:\n",
    "\n",
    "    def __init__(self, rand=None, n=50):\n",
    "        self.n = n\n",
    "        self.rand = rand\n",
    "        self.rftree = Tree(rand = rand, \n",
    "                           get_candidate_columns = random_sqrt_columns, \n",
    "                           min_samples = 2)  # initialize the tree properly\n",
    "\n",
    "    def build(self, X, y):\n",
    "        random_trees = []\n",
    "        oob_list = []\n",
    "        for i in range(self.n):\n",
    "            bootstrap_indices = self.rand.choices(range(len(X)), k = len(X))\n",
    "            out_of_bag_indices = np.setdiff1d(range(X.shape[0]), bootstrap_indices)\n",
    "            #out_of_bag_indices = list(set(range(len(X))).difference(bootstrap_indices))\n",
    "            \n",
    "            random_trees.append(self.rftree.build(X[bootstrap_indices], y[bootstrap_indices]))\n",
    "            oob_list.append(out_of_bag_indices)\n",
    "        \n",
    "        return RFModel(random_trees, oob_list, X, y, self.rand)\n",
    "\n",
    "\n",
    "class RFModel:\n",
    "\n",
    "    def __init__(self, tree_list, oob_list, X, y, rand):\n",
    "        self.tree_list = tree_list\n",
    "        self.oob_list = oob_list\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.rand = rand\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = np.zeros(len(X))\n",
    "        for tree in self.tree_list:\n",
    "            predictions += tree.predict(X)\n",
    "        \n",
    "        return (np.round(predictions/len(self.tree_list)))\n",
    "    \n",
    "\n",
    "    def importance(self):\n",
    "        \n",
    "        imps = np.zeros(self.X.shape[1])\n",
    "\n",
    "        for i, tree in enumerate(self.tree_list):\n",
    "            oob_indices = self.oob_list[i]\n",
    "            X_oob = self.X[oob_indices].copy() # get an oob subset of X for predictions and shuffling\n",
    "            baseline = misclassification_rate(tree.predict(X_oob),\n",
    "                                              self.y[oob_indices])\n",
    "            scores = np.zeros(self.X.shape[1])\n",
    "\n",
    "            for j in range(self.X.shape[1]):\n",
    "                temp = X_oob.copy()\n",
    "                np.random.shuffle(temp[:,j]) # shuffle but without using the seed\n",
    "                score = misclassification_rate(tree.predict(temp),\n",
    "                                               self.y[oob_indices])\n",
    "\n",
    "                scores[j] = score - baseline # feature score for j-th feature in i-th tree\n",
    "\n",
    "            imps += scores\n",
    "\n",
    "        return imps/len(self.tree_list)\n",
    "    \n",
    "def misclassification_rate(prediction, y):\n",
    "    return np.mean(prediction != y)\n",
    "\n",
    "def bootstrap(prediction, y, m=100):\n",
    "    \"\"\"Take an array of predictions and true values and return a bootstrap standard deviation.\"\"\"\n",
    "    bst = []\n",
    "    for i in range(m):\n",
    "        bootstrap_i = np.random.choice(range(len(prediction)),len(prediction))\n",
    "        bst.append(misclassification_rate(prediction[bootstrap_i], y[bootstrap_i]))\n",
    "    \n",
    "    return(np.mean(bst), np.var(bst)) # return mean and variance of the bootstrap \n",
    "\n",
    "def hw_tree_full(train, test):\n",
    "    \"\"\"In function hw_tree_full, build a tree with min_samples=2.\n",
    "    Return misclassification rates and standard errors (to quantify uncertainty) on training and testing data.\"\"\"\n",
    "    (X_train, y_train), (X_test, y_test) = train, test\n",
    "\n",
    "    T = Tree(min_samples=2)\n",
    "    tree = T.build(X_train, y_train)\n",
    "\n",
    "    return (bootstrap(tree.predict(X_train), y_train), bootstrap(tree.predict(X_test), y_test))\n",
    "\n",
    "def hw_randomforests(train, test):\n",
    "    \"\"\"In function hw_randomforest, use random forests with n=100 trees with min_samples=2. \n",
    "    Return misclassification rates and standard errors (to quantify uncertainty) on training and testing data.\"\"\"\n",
    "    (X_train, y_train), (X_test, y_test) = train, test\n",
    "\n",
    "    F = RandomForest(rand = random.Random(3), n=100)\n",
    "    rf = F.build(X_train, y_train)\n",
    "\n",
    "    return(bootstrap(rf.predict(X_train), y_train), bootstrap(rf.predict(X_test), y_test))\n",
    "\n",
    "def tki():\n",
    "    train, test = get_data()\n",
    "    legend = {\"Bcr-abl\":0, \"Wild type\":1}\n",
    "\n",
    "    return train, test, legend\n",
    "    \n",
    "# this works\n",
    "# if __name__ == \"__main__\":\n",
    "#     learn, test, legend = tki()\n",
    "\n",
    "#     print(\"full\", hw_tree_full(learn, test))\n",
    "#     print(\"random forests\", hw_randomforests(learn, test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7df3559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.0, 0.0), (0.18982758620689658, 0.003124227110582639))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hw_tree_full(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5affd1e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.0, 0.0), (0.03689655172413794, 0.0005827586206896552))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hw_randomforests(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e6261a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, (0.25551724137931037, 0.00317705112960761))\n",
      "(2, (0.17172413793103444, 0.0022646848989298454))\n",
      "(3, (0.2022413793103448, 0.002650743162901308))\n",
      "(4, (0.14017241379310344, 0.002185820451843044))\n",
      "(5, (0.15413793103448278, 0.001925208085612366))\n",
      "(7, (0.08965517241379312, 0.001474435196195006))\n",
      "(10, (0.06965517241379313, 0.000915101070154578))\n",
      "(15, (0.05413793103448276, 0.0008146254458977411))\n",
      "(20, (0.05017241379310345, 0.0008745243757431628))\n",
      "(25, (0.034482758620689655, 0.0005291319857312723))\n",
      "(30, (0.03551724137931035, 0.0005994054696789536))\n",
      "(40, (0.07689655172413792, 0.001155885850178359))\n",
      "(50, (0.06672413793103447, 0.0008362366230677764))\n",
      "(65, (0.03517241379310345, 0.0007070154577883473))\n",
      "(80, (0.017241379310344827, 0.0002734839476813317))\n",
      "(100, (0.03568965517241379, 0.0005722651605231867))\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for i in [1,2,3,4,5,7,10,15,20,25,30,40,50,65,80,100]:\n",
    "    F = RandomForest(rand=random.Random(3), n = i)\n",
    "    forest = F.build(train[0],train[1])\n",
    "    print((i, bootstrap(forest.predict(test[0]), test[1])))\n",
    "    results.append((i, bootstrap(forest.predict(test[0]), test[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5c52a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2f4b7b1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.08310344827586208, 0.0011437574316290132)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bootstrap(predictor.predict(test[0]), test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22f6faa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c8c750",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = Tree(get_candidate_columns=random_sqrt_columns, rand = random.Random(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1578600f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = T.build(X1[:130], y1[:130])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117f8ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_prediction = pr.predict(X1[130:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a59450a",
   "metadata": {},
   "outputs": [],
   "source": [
    "misclassification_rate(tree_prediction, y1[130:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a99b941",
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap(tree_prediction, y1[130:], 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905dcdeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e89d5333",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF = RandomForest(rand=random.Random(420), n = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a2e26ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = RF.build(train[0], train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a479166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1.,\n",
       "       1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1.,\n",
       "       1., 0., 0., 0., 0., 1., 0.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.predict(test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce7ae8e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08620689655172414"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassification_rate(predictor.predict(test[0]), test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e867039",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c7c169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n = 50 Miscl.: 0.12068"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44ff3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50):\n",
    "    RF = RandomForest(rand=random.Random(i), n = 100)\n",
    "    predictor = RF.build(X1[:130],y1[:130])\n",
    "    print(np.mean(predictor.predict(X1[130:]) != y1[130:]), i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185fd645",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f47ca1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "imp = predictor.importance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8dfb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "max(imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b34876",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451d4ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argsort(imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041122bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

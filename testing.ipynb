{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41607861",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37ad13cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"tki-resistance.csv\")\n",
    "data[\"Class\"] = data[\"Class\"].map({\"Bcr-abl\":0, \"Wild type\":1})\n",
    "X1, y1 = np.array(data)[:,0:-1], np.array(data)[:,-1]\n",
    "train_X, train_y = X1[:130], y1[:130]\n",
    "test_X, test_y = X1[130:], y1[130:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4e6847f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_columns(X, rand):\n",
    "    return range(X.shape[1])\n",
    "\n",
    "\n",
    "def random_sqrt_columns(X, rand):\n",
    "    c = rand.sample(range(0, X.shape[1]), round(X.shape[1]**0.5))\n",
    "    return c\n",
    "\n",
    "\n",
    "class Tree:\n",
    "\n",
    "    def __init__(self, rand=None,\n",
    "                 get_candidate_columns=all_columns,\n",
    "                 min_samples=2):\n",
    "        self.rand = rand  # for replicability\n",
    "        self.get_candidate_columns = get_candidate_columns  # needed for random forests\n",
    "        self.min_samples = min_samples \n",
    "    \n",
    "    def build(self, X: np.array, y: np.array):\n",
    "        \"\"\"\n",
    "        Recusrively build a tree, stop recursion when a split has a child node with gini impurity 0 or\n",
    "        when we have less than min_samples samples.\n",
    "        \"\"\"\n",
    "        if (len(y) < self.min_samples): # we are in a leaf node\n",
    "            return TreeNode(None, None, round(np.mean(y))) # make the majority class the prediction for this node\n",
    "        if (np.all(y == 1)): # check if we have a node with all ones\n",
    "            return TreeNode(None, None, 1)\n",
    "        if (np.all(y == 0)):\n",
    "            return TreeNode(None, None, 0)\n",
    "        \n",
    "        decision_rule = self.find_decision_rule(X, y)\n",
    "        feature, split_value = decision_rule\n",
    "        \n",
    "        left_i = np.where(X[:,feature] < split_value)\n",
    "        right_i = np.where(X[:, feature] >= split_value)\n",
    "        \n",
    "        left_subtree = Tree()\n",
    "        right_subtree = Tree()\n",
    "        \n",
    "        return TreeNode(left_subtree.build(X[left_i], y[left_i]),\n",
    "                        right_subtree.build(X[right_i], y[right_i]), \n",
    "                        decision_rule) \n",
    "    \n",
    "    \n",
    "    def find_decision_rule(self, X, y):\n",
    "        \"\"\"\n",
    "        Input: X - data, y - labels\n",
    "        Output: A tuple (left, right, decision_rule), left indicies, right indicies and rule. Rule itself is a tuple\n",
    "        of the index of the feature to split on and the value of where to split.)\n",
    "        \"\"\"\n",
    "        decision_rule = None\n",
    "        best_info_gain = 0\n",
    "\n",
    "        for feature in self.get_candidate_columns(X, self.rand):\n",
    "            values = X[:, feature]\n",
    "            sorted_indices = np.argsort(values)\n",
    "            sorted_values = values[sorted_indices]\n",
    "            for i in range(len(sorted_values) - 1):\n",
    "                current_info_gain = self.information_gain(y[sorted_indices], np.arange(0,i+1), np.arange(i+1, len(values)))\n",
    "                \n",
    "                if(current_info_gain > best_info_gain):\n",
    "                    split_value = self.midpoint(i, sorted_values)\n",
    "                    best_info_gain = current_info_gain\n",
    "                    decision_rule = (feature, split_value)\n",
    "\n",
    "        return decision_rule\n",
    "                \n",
    "    def midpoint(self, index, y):\n",
    "        \"\"\"Finds the average value of entires at index i and i+1 in a presumably sorted array.\"\"\"\n",
    "        return (y[index] + y[index + 1])/2\n",
    "    \n",
    "    def information_gain(self, y , left_partition_indicies, right_partition_indicies):\n",
    "        \"\"\"\n",
    "        Input: Takes an array of labels and the indicies of which belong to the lefr and right partition.\n",
    "        Output: Returns information gain for this particular split.\n",
    "        \"\"\"\n",
    "        n_left = len(left_partition_indicies)\n",
    "        n_right = len(right_partition_indicies)\n",
    "        n = n_left + n_right\n",
    "\n",
    "        l_weight = n_left/n\n",
    "        r_weight = n_right/n\n",
    "\n",
    "        inf_gain = (self.gini_impurity(y) \n",
    "                    - self.gini_impurity(y[left_partition_indicies])*l_weight \n",
    "                    - self.gini_impurity(y[right_partition_indicies])*r_weight)\n",
    "\n",
    "        return inf_gain\n",
    "\n",
    "    def gini_impurity(self, y):\n",
    "        \"\"\"\n",
    "        We can use this simplified version because we are solving a strictly binary classification problem, \n",
    "        assume y is a numpy array with values of 0 or 1.\n",
    "        \"\"\"\n",
    "\n",
    "        label_one_probability = sum(y)/len(y)\n",
    "\n",
    "        return 1 - ((label_one_probability)**2 + (1-label_one_probability)**2)\n",
    "\n",
    "\n",
    "class TreeNode:\n",
    "    \n",
    "    def __init__(self, left, right, decision_rule):\n",
    "        \"\"\"Left and right are TreeNode objects. Decision rule is either a tuple with a feature and value \n",
    "        to split on or a single value which determines the leaf's predicted label.\n",
    "        \"\"\"\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.decision_rule = decision_rule\n",
    "\n",
    "    def predict(self, X):\n",
    "        prediction = np.empty(len(X))\n",
    "        \n",
    "        if ((self.left is None) and (self.right is None)): # we are in a leaf node\n",
    "            return self.decision_rule\n",
    "        \n",
    "        # get left and right indices\n",
    "        left_i = np.where(X.T[self.decision_rule[0]] < self.decision_rule[1])\n",
    "        right_i = np.where(X.T[self.decision_rule[0]] >= self.decision_rule[1])\n",
    "        \n",
    "        left_prediction = self.left.predict(X[left_i])\n",
    "        right_prediction = self.right.predict(X[right_i])\n",
    "        \n",
    "        prediction[left_i] = left_prediction\n",
    "        prediction[right_i] = right_prediction\n",
    "               \n",
    "        return prediction\n",
    "\n",
    "\n",
    "class RandomForest:\n",
    "\n",
    "    def __init__(self, rand=None, n=50):\n",
    "        self.n = n\n",
    "        self.rand = rand\n",
    "        self.rftree = Tree(rand = rand, \n",
    "                           get_candidate_columns = random_sqrt_columns, \n",
    "                           min_samples = 2)  # initialize the tree properly\n",
    "\n",
    "    def build(self, X, y):\n",
    "        random_trees = []\n",
    "        oob_list = []\n",
    "        for i in range(self.n):\n",
    "            bootstrap_indices = self.rand.choices(range(len(X)), k = len(X))\n",
    "            out_of_bag_indices = np.setdiff1d(range(X.shape[0]), bootstrap_indices)\n",
    "            #out_of_bag_indices = list(set(range(len(X))).difference(bootstrap_indices))\n",
    "            \n",
    "            random_trees.append(self.rftree.build(X[bootstrap_indices], y[bootstrap_indices]))\n",
    "            oob_list.append(out_of_bag_indices)\n",
    "        \n",
    "        return RFModel(random_trees, oob_list, X, y, self.rand)\n",
    "\n",
    "\n",
    "class RFModel:\n",
    "\n",
    "    def __init__(self, tree_list, oob_list, X, y, rand):\n",
    "        self.tree_list = tree_list\n",
    "        self.oob_list = oob_list\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.rand = rand\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = np.zeros(len(X))\n",
    "        for tree in self.tree_list:\n",
    "            predictions += tree.predict(X)\n",
    "        \n",
    "        return (np.round(predictions/len(self.tree_list)))\n",
    "    \n",
    "\n",
    "    def importance(self):\n",
    "        \n",
    "        imps = np.zeros(self.X.shape[1])\n",
    "\n",
    "        for i, tree in enumerate(self.tree_list):\n",
    "            oob_indices = self.oob_list[i]\n",
    "            X_oob = self.X[oob_indices].copy() # get an oob subset of X for predictions and shuffling\n",
    "            baseline = misclassification_rate(tree.predict(X_oob),\n",
    "                                              self.y[oob_indices])\n",
    "            scores = np.zeros(self.X.shape[1])\n",
    "\n",
    "            for j in range(self.X.shape[1]):\n",
    "                temp = X_oob.copy()\n",
    "                np.random.shuffle(temp[:,j]) # shuffle but without using the seed\n",
    "                score = misclassification_rate(tree.predict(temp),\n",
    "                                               self.y[oob_indices])\n",
    "\n",
    "                scores[j] = score - baseline # feature score for j-th feature in i-th tree\n",
    "\n",
    "            imps += scores\n",
    "\n",
    "        return imps/len(self.tree_list)\n",
    "    \n",
    "def misclassification_rate(prediction, y):\n",
    "    return np.mean(prediction != y)\n",
    "\n",
    "def prediction_uncertainty(prediction, y):\n",
    "    \"\"\"\n",
    "    Input: a prediction array and a label array.\n",
    "    Output: A tuple (average, std) of the prediction uncertainty.\n",
    "    \"\"\"\n",
    "    x = 0\n",
    "    for i in range(len(y)):\n",
    "        x += (prediction[i] - y[i])**2\n",
    "        \n",
    "    print((x/(len(y)-1))**0.5)\n",
    "    print(np.std(prediction != y))\n",
    "    #return (np.mean(misclassification), np.std(misclassification))\n",
    "    \n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     learn, test, legend = tki()\n",
    "\n",
    "#     print(\"full\", hw_tree_full(learn, test))\n",
    "#     print(\"random forests\", hw_randomforests(learn, test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c8c750",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = Tree(get_candidate_columns=random_sqrt_columns, rand = random.Random(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1578600f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = T.build(X1[:130], y1[:130])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117f8ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr.predict(X1[130:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66129aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(pr.predict(X1[130:]) != y1[130:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0993b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1.shape[0] == len(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905dcdeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e89d5333",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF = RandomForest(rand=random.Random(420), n = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a2e26ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = RF.build(X1[:130],y1[:130])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a479166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0.,\n",
       "       1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
       "       0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 1., 0.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.predict(X1[130:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b7d01af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06896551724137931"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(predictor.predict(X1[130:]) != y1[130:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c7c169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n = 50 Miscl.: 0.12068"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d44ff3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10344827586206896 0\n",
      "0.08620689655172414 1\n",
      "0.08620689655172414 2\n",
      "0.034482758620689655 3\n",
      "0.034482758620689655 4\n",
      "0.05172413793103448 5\n",
      "0.05172413793103448 6\n",
      "0.05172413793103448 7\n",
      "0.05172413793103448 8\n",
      "0.1206896551724138 9\n",
      "0.10344827586206896 10\n",
      "0.13793103448275862 11\n",
      "0.05172413793103448 12\n",
      "0.06896551724137931 13\n",
      "0.10344827586206896 14\n",
      "0.08620689655172414 15\n",
      "0.05172413793103448 16\n",
      "0.06896551724137931 17\n",
      "0.05172413793103448 18\n",
      "0.08620689655172414 19\n",
      "0.13793103448275862 20\n",
      "0.034482758620689655 21\n",
      "0.05172413793103448 22\n",
      "0.08620689655172414 23\n",
      "0.034482758620689655 24\n",
      "0.06896551724137931 25\n",
      "0.034482758620689655 26\n",
      "0.08620689655172414 27\n",
      "0.05172413793103448 28\n",
      "0.08620689655172414 29\n",
      "0.06896551724137931 30\n",
      "0.06896551724137931 31\n",
      "0.034482758620689655 32\n",
      "0.08620689655172414 33\n",
      "0.06896551724137931 34\n",
      "0.06896551724137931 35\n",
      "0.05172413793103448 36\n",
      "0.06896551724137931 37\n",
      "0.06896551724137931 38\n",
      "0.05172413793103448 39\n",
      "0.06896551724137931 40\n",
      "0.06896551724137931 41\n",
      "0.06896551724137931 42\n",
      "0.08620689655172414 43\n",
      "0.06896551724137931 44\n",
      "0.05172413793103448 45\n",
      "0.08620689655172414 46\n",
      "0.05172413793103448 47\n",
      "0.10344827586206896 48\n",
      "0.10344827586206896 49\n"
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "    RF = RandomForest(rand=random.Random(i), n = 100)\n",
    "    predictor = RF.build(X1[:130],y1[:130])\n",
    "    print(np.mean(predictor.predict(X1[130:]) != y1[130:]), i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185fd645",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f47ca1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "imp = predictor.importance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8dfb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "max(imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b34876",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451d4ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argsort(imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041122bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
